{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Universidad Nacional de Colombia**\n",
    "\n",
    "**Diplomado en Inteligencia Artificial y Aprendizaje Profundo**\n",
    "\n",
    "**Leidy Natalia León Carvajal**\n",
    "\n",
    "**lnleonc@unal.edu.co**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Regresión y Clasificación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Punto 1: Breast Cancer Winsconsin**\n",
    "\n",
    "### Construya una red neuronal de clasificación binaria para predecir el cáncer de seno. Use los datos Breast Cancer Wisconsin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importaremos las librerías necesarias para trabajar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.estimator import LinearClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "# Cargamos los modelos\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargaremos ahora la base de datos obtenida de [https://www.kaggle.com/uciml/breast-cancer-wisconsin-data](https://www.kaggle.com/uciml/breast-cancer-wisconsin-data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cancer=pd.read_csv('/home/natalia/Documentos/Jupyter Lab/breastcancer.csv')\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retiramos la última columna que contiene 'Nan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  radius_worst  texture_worst  perimeter_worst  area_worst  \\\n",
       "0  ...         25.38          17.33           184.60      2019.0   \n",
       "1  ...         24.99          23.41           158.80      1956.0   \n",
       "2  ...         23.57          25.53           152.50      1709.0   \n",
       "3  ...         14.91          26.50            98.87       567.7   \n",
       "4  ...         22.54          16.67           152.20      1575.0   \n",
       "\n",
       "   smoothness_worst  compactness_worst  concavity_worst  concave points_worst  \\\n",
       "0            0.1622             0.6656           0.7119                0.2654   \n",
       "1            0.1238             0.1866           0.2416                0.1860   \n",
       "2            0.1444             0.4245           0.4504                0.2430   \n",
       "3            0.2098             0.8663           0.6869                0.2575   \n",
       "4            0.1374             0.2050           0.4000                0.1625   \n",
       "\n",
       "   symmetry_worst  fractal_dimension_worst  \n",
       "0          0.4601                  0.11890  \n",
       "1          0.2750                  0.08902  \n",
       "2          0.3613                  0.08758  \n",
       "3          0.6638                  0.17300  \n",
       "4          0.2364                  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del cancer['Unnamed: 32']\n",
    "cancer.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizaremos ahora un preprocesamiento de los datos, eligiendo a la variable **diagnosis** como dependiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.799e+01 1.038e+01 1.228e+02 ... 2.654e-01 4.601e-01 1.189e-01]\n",
      " [2.057e+01 1.777e+01 1.329e+02 ... 1.860e-01 2.750e-01 8.902e-02]\n",
      " [1.969e+01 2.125e+01 1.300e+02 ... 2.430e-01 3.613e-01 8.758e-02]\n",
      " ...\n",
      " [1.660e+01 2.808e+01 1.083e+02 ... 1.418e-01 2.218e-01 7.820e-02]\n",
      " [2.060e+01 2.933e+01 1.401e+02 ... 2.650e-01 4.087e-01 1.240e-01]\n",
      " [7.760e+00 2.454e+01 4.792e+01 ... 0.000e+00 2.871e-01 7.039e-02]]\n",
      "['M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M'\n",
      " 'M' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M'\n",
      " 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B'\n",
      " 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'B'\n",
      " 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'M'\n",
      " 'M' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B'\n",
      " 'M' 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'M' 'M'\n",
      " 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'M' 'M'\n",
      " 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'M'\n",
      " 'B' 'B' 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'M' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'M' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B'\n",
      " 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B'\n",
      " 'M' 'M' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'B' 'M'\n",
      " 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'M' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'M' 'B' 'M' 'B' 'B' 'M' 'B' 'B' 'B' 'B' 'B' 'M' 'M' 'B' 'M' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'B' 'M' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B' 'M'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'M' 'B' 'M' 'M' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B' 'B'\n",
      " 'B' 'B' 'B' 'B' 'M' 'M' 'M' 'M' 'M' 'M' 'B']\n"
     ]
    }
   ],
   "source": [
    "x = cancer.iloc[:,2:].values # extrae como tensores numpy\n",
    "y = cancer.iloc[:,1].values\n",
    "\n",
    "print(x)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recodificamos ahora la variable **diagnosis**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 1 1 1 1 1 1 1 1 0 1 0 0 0 0 0 1 1 0 1 1 0 0 0 0 1 0 1 1 0 0 0 0 1 0 1 1\n",
      " 0 1 0 1 1 0 0 0 1 1 0 1 1 1 0 0 0 1 0 0 1 1 0 0 0 1 1 0 0 0 0 1 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 1 1 0 1 1 0 0 0 1 1 0 1 0 1 1 0 1 1 0 0 1 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 1 0 0 1 1 0 0 1 1 0 0 0 0 1 0 0 1 1 1 0 1\n",
      " 0 1 0 0 0 1 0 0 1 1 0 1 1 1 1 0 1 1 1 0 1 0 1 0 0 1 0 1 1 1 1 0 0 1 1 0 0\n",
      " 0 1 0 0 0 0 0 1 1 0 0 1 0 0 1 1 0 1 0 0 0 0 1 0 0 0 0 0 1 0 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 0 0 0 0 0 0 1 0 1 0 0 1 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 0 1 1 1 0 0\n",
      " 0 0 1 0 1 0 1 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 1\n",
      " 1 0 1 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 1 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 1 0 0 0 0 0 1 0 0\n",
      " 1 0 1 0 0 1 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 0 1 1 0 1 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 1\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 1 1 1 1 1 0]\n"
     ]
    }
   ],
   "source": [
    "labelencoder_y = LabelEncoder()\n",
    "diagnosis = labelencoder_y.fit_transform(y)\n",
    "print(diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seleccionaremos nuestro conjunto de datos de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 30)\n",
      "(57, 30)\n"
     ]
    }
   ],
   "source": [
    "x_train, x_test, diag_train, diag_test = train_test_split(x, diagnosis, test_size = 0.1, random_state = 0)\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A continuación estandarizamos las covariables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generamos un modelo secuencial Modo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "clasificador = Sequential()\n",
    "clasificador.add(Dense(units=16, activation='relu', input_shape=(30,)))\n",
    "clasificador.add(Dropout(0.1))\n",
    "clasificador.add(Dense(units=16, activation='relu'))\n",
    "clasificador.add(Dropout(0.1))\n",
    "clasificador.add(Dense(units=1, activation='sigmoid'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamos nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_36 (Dense)             (None, 16)                496       \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 785\n",
      "Trainable params: 785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Usaremos el compilador \"ADAM\"\n",
    "clasificador.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "clasificador.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "13/13 [==============================] - 0s 20ms/step - loss: 0.6977 - accuracy: 0.6259 - val_loss: 0.6028 - val_accuracy: 0.7282\n",
      "Epoch 2/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5837 - accuracy: 0.7531 - val_loss: 0.5072 - val_accuracy: 0.8252\n",
      "Epoch 3/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.5037 - accuracy: 0.8215 - val_loss: 0.4249 - val_accuracy: 0.8932\n",
      "Epoch 4/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.4238 - accuracy: 0.8680 - val_loss: 0.3546 - val_accuracy: 0.9515\n",
      "Epoch 5/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.3764 - accuracy: 0.8826 - val_loss: 0.2951 - val_accuracy: 0.9709\n",
      "Epoch 6/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2993 - accuracy: 0.9218 - val_loss: 0.2437 - val_accuracy: 0.9806\n",
      "Epoch 7/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2766 - accuracy: 0.9218 - val_loss: 0.2014 - val_accuracy: 0.9903\n",
      "Epoch 8/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2439 - accuracy: 0.9242 - val_loss: 0.1702 - val_accuracy: 0.9903\n",
      "Epoch 9/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.2099 - accuracy: 0.9364 - val_loss: 0.1472 - val_accuracy: 0.9806\n",
      "Epoch 10/150\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.1879 - accuracy: 0.9413 - val_loss: 0.1283 - val_accuracy: 0.9806\n",
      "Epoch 11/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1650 - accuracy: 0.9438 - val_loss: 0.1125 - val_accuracy: 0.9806\n",
      "Epoch 12/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.1517 - accuracy: 0.9560 - val_loss: 0.1000 - val_accuracy: 0.9806\n",
      "Epoch 13/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1499 - accuracy: 0.9487 - val_loss: 0.0903 - val_accuracy: 0.9806\n",
      "Epoch 14/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1299 - accuracy: 0.9584 - val_loss: 0.0832 - val_accuracy: 0.9806\n",
      "Epoch 15/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1306 - accuracy: 0.9560 - val_loss: 0.0762 - val_accuracy: 0.9806\n",
      "Epoch 16/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.1145 - accuracy: 0.9609 - val_loss: 0.0704 - val_accuracy: 0.9806\n",
      "Epoch 17/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1003 - accuracy: 0.9707 - val_loss: 0.0651 - val_accuracy: 0.9806\n",
      "Epoch 18/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1084 - accuracy: 0.9658 - val_loss: 0.0600 - val_accuracy: 0.9806\n",
      "Epoch 19/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.1059 - accuracy: 0.9682 - val_loss: 0.0574 - val_accuracy: 0.9806\n",
      "Epoch 20/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.1033 - accuracy: 0.9707 - val_loss: 0.0546 - val_accuracy: 0.9806\n",
      "Epoch 21/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.1028 - accuracy: 0.9707 - val_loss: 0.0511 - val_accuracy: 0.9806\n",
      "Epoch 22/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0877 - accuracy: 0.9707 - val_loss: 0.0497 - val_accuracy: 0.9806\n",
      "Epoch 23/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0882 - accuracy: 0.9658 - val_loss: 0.0481 - val_accuracy: 0.9903\n",
      "Epoch 24/150\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0786 - accuracy: 0.9731 - val_loss: 0.0462 - val_accuracy: 0.9903\n",
      "Epoch 25/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.9707 - val_loss: 0.0431 - val_accuracy: 0.9806\n",
      "Epoch 26/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0717 - accuracy: 0.9756 - val_loss: 0.0417 - val_accuracy: 0.9806\n",
      "Epoch 27/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0809 - accuracy: 0.9609 - val_loss: 0.0405 - val_accuracy: 0.9806\n",
      "Epoch 28/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0708 - accuracy: 0.9829 - val_loss: 0.0408 - val_accuracy: 0.9903\n",
      "Epoch 29/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0768 - accuracy: 0.9633 - val_loss: 0.0405 - val_accuracy: 0.9903\n",
      "Epoch 30/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0708 - accuracy: 0.9756 - val_loss: 0.0399 - val_accuracy: 0.9903\n",
      "Epoch 31/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0718 - accuracy: 0.9780 - val_loss: 0.0385 - val_accuracy: 0.9903\n",
      "Epoch 32/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0711 - accuracy: 0.9731 - val_loss: 0.0385 - val_accuracy: 0.9903\n",
      "Epoch 33/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0672 - accuracy: 0.9756 - val_loss: 0.0379 - val_accuracy: 0.9806\n",
      "Epoch 34/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0652 - accuracy: 0.9804 - val_loss: 0.0374 - val_accuracy: 0.9806\n",
      "Epoch 35/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0702 - accuracy: 0.9804 - val_loss: 0.0371 - val_accuracy: 0.9806\n",
      "Epoch 36/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0643 - accuracy: 0.9756 - val_loss: 0.0377 - val_accuracy: 0.9903\n",
      "Epoch 37/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0631 - accuracy: 0.9804 - val_loss: 0.0372 - val_accuracy: 0.9806\n",
      "Epoch 38/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0541 - accuracy: 0.9804 - val_loss: 0.0364 - val_accuracy: 0.9806\n",
      "Epoch 39/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0632 - accuracy: 0.9780 - val_loss: 0.0348 - val_accuracy: 0.9903\n",
      "Epoch 40/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0577 - accuracy: 0.9853 - val_loss: 0.0356 - val_accuracy: 0.9903\n",
      "Epoch 41/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0590 - accuracy: 0.9780 - val_loss: 0.0348 - val_accuracy: 0.9903\n",
      "Epoch 42/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0488 - accuracy: 0.9853 - val_loss: 0.0342 - val_accuracy: 0.9903\n",
      "Epoch 43/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0546 - accuracy: 0.9780 - val_loss: 0.0327 - val_accuracy: 0.9903\n",
      "Epoch 44/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0627 - accuracy: 0.9780 - val_loss: 0.0327 - val_accuracy: 0.9903\n",
      "Epoch 45/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0519 - accuracy: 0.9804 - val_loss: 0.0326 - val_accuracy: 0.9806\n",
      "Epoch 46/150\n",
      "13/13 [==============================] - 0s 13ms/step - loss: 0.0615 - accuracy: 0.9780 - val_loss: 0.0318 - val_accuracy: 0.9903\n",
      "Epoch 47/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0535 - accuracy: 0.9829 - val_loss: 0.0321 - val_accuracy: 0.9903\n",
      "Epoch 48/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0533 - accuracy: 0.9731 - val_loss: 0.0330 - val_accuracy: 0.9903\n",
      "Epoch 49/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0424 - accuracy: 0.9804 - val_loss: 0.0338 - val_accuracy: 0.9903\n",
      "Epoch 50/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0431 - accuracy: 0.9829 - val_loss: 0.0334 - val_accuracy: 0.9903\n",
      "Epoch 51/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0491 - accuracy: 0.9780 - val_loss: 0.0321 - val_accuracy: 0.9903\n",
      "Epoch 52/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0557 - accuracy: 0.9804 - val_loss: 0.0299 - val_accuracy: 0.9806\n",
      "Epoch 53/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0474 - accuracy: 0.9878 - val_loss: 0.0307 - val_accuracy: 0.9806\n",
      "Epoch 54/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 0.0305 - val_accuracy: 0.9806\n",
      "Epoch 55/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0499 - accuracy: 0.9829 - val_loss: 0.0313 - val_accuracy: 0.9806\n",
      "Epoch 56/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0471 - accuracy: 0.9853 - val_loss: 0.0313 - val_accuracy: 0.9806\n",
      "Epoch 57/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0466 - accuracy: 0.9804 - val_loss: 0.0286 - val_accuracy: 0.9806\n",
      "Epoch 58/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0385 - accuracy: 0.9878 - val_loss: 0.0307 - val_accuracy: 0.9903\n",
      "Epoch 59/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0391 - accuracy: 0.9902 - val_loss: 0.0298 - val_accuracy: 0.9903\n",
      "Epoch 60/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0371 - accuracy: 0.9853 - val_loss: 0.0294 - val_accuracy: 0.9903\n",
      "Epoch 61/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 0.0291 - val_accuracy: 0.9903\n",
      "Epoch 62/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9902 - val_loss: 0.0288 - val_accuracy: 0.9806\n",
      "Epoch 63/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0468 - accuracy: 0.9853 - val_loss: 0.0275 - val_accuracy: 0.9903\n",
      "Epoch 64/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0324 - accuracy: 0.9902 - val_loss: 0.0275 - val_accuracy: 0.9806\n",
      "Epoch 65/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0356 - accuracy: 0.9878 - val_loss: 0.0259 - val_accuracy: 0.9903\n",
      "Epoch 66/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0492 - accuracy: 0.9878 - val_loss: 0.0256 - val_accuracy: 0.9903\n",
      "Epoch 67/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0511 - accuracy: 0.9804 - val_loss: 0.0261 - val_accuracy: 0.9903\n",
      "Epoch 68/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0302 - accuracy: 0.9927 - val_loss: 0.0258 - val_accuracy: 0.9903\n",
      "Epoch 69/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0415 - accuracy: 0.9829 - val_loss: 0.0252 - val_accuracy: 0.9903\n",
      "Epoch 70/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0537 - accuracy: 0.9756 - val_loss: 0.0265 - val_accuracy: 0.9903\n",
      "Epoch 71/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9853 - val_loss: 0.0255 - val_accuracy: 0.9903\n",
      "Epoch 72/150\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0416 - accuracy: 0.9829 - val_loss: 0.0248 - val_accuracy: 0.9903\n",
      "Epoch 73/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0425 - accuracy: 0.9853 - val_loss: 0.0245 - val_accuracy: 0.9903\n",
      "Epoch 74/150\n",
      "13/13 [==============================] - 0s 21ms/step - loss: 0.0387 - accuracy: 0.9927 - val_loss: 0.0245 - val_accuracy: 0.9903\n",
      "Epoch 75/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0283 - accuracy: 0.9927 - val_loss: 0.0252 - val_accuracy: 0.9903\n",
      "Epoch 76/150\n",
      "13/13 [==============================] - 0s 17ms/step - loss: 0.0360 - accuracy: 0.9878 - val_loss: 0.0228 - val_accuracy: 0.9903\n",
      "Epoch 77/150\n",
      "13/13 [==============================] - 0s 16ms/step - loss: 0.0452 - accuracy: 0.9878 - val_loss: 0.0235 - val_accuracy: 0.9903\n",
      "Epoch 78/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0384 - accuracy: 0.9804 - val_loss: 0.0227 - val_accuracy: 0.9903\n",
      "Epoch 79/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0299 - accuracy: 0.9878 - val_loss: 0.0249 - val_accuracy: 0.9903\n",
      "Epoch 80/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0354 - accuracy: 0.9902 - val_loss: 0.0234 - val_accuracy: 0.9903\n",
      "Epoch 81/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0394 - accuracy: 0.9804 - val_loss: 0.0219 - val_accuracy: 0.9903\n",
      "Epoch 82/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0244 - accuracy: 0.9902 - val_loss: 0.0233 - val_accuracy: 0.9903\n",
      "Epoch 83/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0318 - accuracy: 0.9878 - val_loss: 0.0236 - val_accuracy: 0.9903\n",
      "Epoch 84/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0384 - accuracy: 0.9853 - val_loss: 0.0234 - val_accuracy: 0.9903\n",
      "Epoch 85/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0323 - accuracy: 0.9878 - val_loss: 0.0238 - val_accuracy: 0.9903\n",
      "Epoch 86/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0293 - accuracy: 0.9902 - val_loss: 0.0241 - val_accuracy: 0.9903\n",
      "Epoch 87/150\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 0.0386 - accuracy: 0.9878 - val_loss: 0.0240 - val_accuracy: 0.9903\n",
      "Epoch 88/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0310 - accuracy: 0.9878 - val_loss: 0.0222 - val_accuracy: 0.9903\n",
      "Epoch 89/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0389 - accuracy: 0.9829 - val_loss: 0.0226 - val_accuracy: 0.9903\n",
      "Epoch 90/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0279 - accuracy: 0.9927 - val_loss: 0.0245 - val_accuracy: 0.9903\n",
      "Epoch 91/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0283 - accuracy: 0.9853 - val_loss: 0.0247 - val_accuracy: 0.9903\n",
      "Epoch 92/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0351 - accuracy: 0.9804 - val_loss: 0.0252 - val_accuracy: 0.9903\n",
      "Epoch 93/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0338 - accuracy: 0.9853 - val_loss: 0.0243 - val_accuracy: 0.9903\n",
      "Epoch 94/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0285 - accuracy: 0.9878 - val_loss: 0.0219 - val_accuracy: 0.9903\n",
      "Epoch 95/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0270 - accuracy: 0.9878 - val_loss: 0.0222 - val_accuracy: 0.9903\n",
      "Epoch 96/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0363 - accuracy: 0.9927 - val_loss: 0.0222 - val_accuracy: 0.9903\n",
      "Epoch 97/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0341 - accuracy: 0.9902 - val_loss: 0.0223 - val_accuracy: 0.9903\n",
      "Epoch 98/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0266 - accuracy: 0.9878 - val_loss: 0.0229 - val_accuracy: 0.9903\n",
      "Epoch 99/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0357 - accuracy: 0.9878 - val_loss: 0.0224 - val_accuracy: 0.9903\n",
      "Epoch 100/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0224 - accuracy: 0.9927 - val_loss: 0.0222 - val_accuracy: 0.9903\n",
      "Epoch 101/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0352 - accuracy: 0.9878 - val_loss: 0.0234 - val_accuracy: 0.9903\n",
      "Epoch 102/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0401 - accuracy: 0.9829 - val_loss: 0.0235 - val_accuracy: 0.9903\n",
      "Epoch 103/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0265 - accuracy: 0.9853 - val_loss: 0.0226 - val_accuracy: 0.9903\n",
      "Epoch 104/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9902 - val_loss: 0.0228 - val_accuracy: 0.9903\n",
      "Epoch 105/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0234 - accuracy: 0.9902 - val_loss: 0.0251 - val_accuracy: 0.9903\n",
      "Epoch 106/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0238 - accuracy: 0.9927 - val_loss: 0.0259 - val_accuracy: 0.9903\n",
      "Epoch 107/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9853 - val_loss: 0.0234 - val_accuracy: 0.9903\n",
      "Epoch 108/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 0.9902 - val_loss: 0.0222 - val_accuracy: 0.9903\n",
      "Epoch 109/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0332 - accuracy: 0.9878 - val_loss: 0.0209 - val_accuracy: 0.9903\n",
      "Epoch 110/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0267 - accuracy: 0.9853 - val_loss: 0.0199 - val_accuracy: 0.9903\n",
      "Epoch 111/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0222 - accuracy: 0.9927 - val_loss: 0.0197 - val_accuracy: 0.9903\n",
      "Epoch 112/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0242 - accuracy: 0.9951 - val_loss: 0.0196 - val_accuracy: 0.9903\n",
      "Epoch 113/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0245 - accuracy: 0.9902 - val_loss: 0.0213 - val_accuracy: 0.9903\n",
      "Epoch 114/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0182 - accuracy: 0.9976 - val_loss: 0.0224 - val_accuracy: 0.9903\n",
      "Epoch 115/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0160 - accuracy: 0.9951 - val_loss: 0.0220 - val_accuracy: 0.9903\n",
      "Epoch 116/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.0213 - val_accuracy: 0.9903\n",
      "Epoch 117/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0269 - accuracy: 0.9902 - val_loss: 0.0217 - val_accuracy: 0.9903\n",
      "Epoch 118/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0188 - accuracy: 0.9976 - val_loss: 0.0222 - val_accuracy: 0.9903\n",
      "Epoch 119/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0197 - accuracy: 0.9927 - val_loss: 0.0212 - val_accuracy: 0.9903\n",
      "Epoch 120/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0187 - accuracy: 0.9927 - val_loss: 0.0202 - val_accuracy: 0.9903\n",
      "Epoch 121/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9927 - val_loss: 0.0196 - val_accuracy: 0.9903\n",
      "Epoch 122/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0159 - accuracy: 0.9951 - val_loss: 0.0202 - val_accuracy: 0.9903\n",
      "Epoch 123/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0218 - accuracy: 0.9902 - val_loss: 0.0200 - val_accuracy: 0.9903\n",
      "Epoch 124/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0312 - accuracy: 0.9878 - val_loss: 0.0174 - val_accuracy: 0.9903\n",
      "Epoch 125/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0287 - accuracy: 0.9878 - val_loss: 0.0161 - val_accuracy: 0.9903\n",
      "Epoch 126/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0234 - accuracy: 0.9853 - val_loss: 0.0169 - val_accuracy: 0.9903\n",
      "Epoch 127/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0326 - accuracy: 0.9853 - val_loss: 0.0193 - val_accuracy: 0.9903\n",
      "Epoch 128/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.0185 - val_accuracy: 0.9903\n",
      "Epoch 129/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0174 - accuracy: 0.9951 - val_loss: 0.0184 - val_accuracy: 0.9903\n",
      "Epoch 130/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0237 - accuracy: 0.9902 - val_loss: 0.0196 - val_accuracy: 0.9903\n",
      "Epoch 131/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0147 - accuracy: 0.9976 - val_loss: 0.0202 - val_accuracy: 0.9903\n",
      "Epoch 132/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0201 - accuracy: 0.9927 - val_loss: 0.0202 - val_accuracy: 0.9903\n",
      "Epoch 133/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0174 - accuracy: 0.9927 - val_loss: 0.0220 - val_accuracy: 0.9903\n",
      "Epoch 134/150\n",
      "13/13 [==============================] - 0s 12ms/step - loss: 0.0292 - accuracy: 0.9902 - val_loss: 0.0198 - val_accuracy: 0.9903\n",
      "Epoch 135/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0229 - accuracy: 0.9878 - val_loss: 0.0178 - val_accuracy: 0.9903\n",
      "Epoch 136/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0233 - accuracy: 0.9927 - val_loss: 0.0171 - val_accuracy: 0.9903\n",
      "Epoch 137/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9878 - val_loss: 0.0183 - val_accuracy: 0.9903\n",
      "Epoch 138/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0235 - accuracy: 0.9878 - val_loss: 0.0185 - val_accuracy: 0.9903\n",
      "Epoch 139/150\n",
      "13/13 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.99 - 0s 8ms/step - loss: 0.0163 - accuracy: 0.9927 - val_loss: 0.0198 - val_accuracy: 0.9903\n",
      "Epoch 140/150\n",
      "13/13 [==============================] - 0s 9ms/step - loss: 0.0128 - accuracy: 0.9976 - val_loss: 0.0190 - val_accuracy: 0.9903\n",
      "Epoch 141/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0168 - accuracy: 0.9927 - val_loss: 0.0187 - val_accuracy: 0.9903\n",
      "Epoch 142/150\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0141 - accuracy: 0.9976 - val_loss: 0.0206 - val_accuracy: 0.9903\n",
      "Epoch 143/150\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0162 - accuracy: 0.9951 - val_loss: 0.0190 - val_accuracy: 0.9903\n",
      "Epoch 144/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0146 - accuracy: 0.9976 - val_loss: 0.0182 - val_accuracy: 0.9903\n",
      "Epoch 145/150\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0216 - accuracy: 0.9951 - val_loss: 0.0186 - val_accuracy: 0.9903\n",
      "Epoch 146/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0206 - accuracy: 0.9951 - val_loss: 0.0202 - val_accuracy: 0.9903\n",
      "Epoch 147/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0203 - accuracy: 0.9927 - val_loss: 0.0180 - val_accuracy: 0.9903\n",
      "Epoch 148/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0200 - accuracy: 0.9951 - val_loss: 0.0169 - val_accuracy: 0.9903\n",
      "Epoch 149/150\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 0.0207 - accuracy: 0.9902 - val_loss: 0.0174 - val_accuracy: 0.9903\n",
      "Epoch 150/150\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0214 - accuracy: 0.9902 - val_loss: 0.0185 - val_accuracy: 0.9903\n"
     ]
    }
   ],
   "source": [
    "historico = clasificador.fit(x_train, diag_train, batch_size=32, epochs=150,validation_split = 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Realizamos las predicciones correspondientes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(57, 1)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diag_pred = clasificador.predict(x_test)\n",
    "diag_pred[diag_pred > 0.5] = 1\n",
    "diag_pred[diag_pred <=0.5] = 0\n",
    "diag_pred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtenemos la matriz de confusión:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nuestro porcentaje de precisión es 94.73684210526315%\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(diag_test, diag_pred)\n",
    "print(\"Nuestro porcentaje de precisión es {}%\".format(((cm[0][0] + cm[1][1])/diag_test.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sb.heatmap(cm,annot=True,cmap=\"Blues\")\n",
    "plt.savefig('h.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalmente evaluaremos nuestro modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_metric(historico, metric):\n",
    "    train_metrics = historico.history[metric]\n",
    "    val_metrics = historico.history['val_'+metric]\n",
    "    epochs = range(1, len(train_metrics) + 1)\n",
    "    plt.plot(epochs, train_metrics, 'bo--')\n",
    "    plt.plot(epochs, val_metrics, 'ro-')\n",
    "    plt.title('Entrenamiento y Validación '+ metric)\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(metric)\n",
    "    plt.legend([\"train_\"+metric, 'val_'+metric])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(historico, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric(historico, 'accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Punto 2: Boston Housing**\n",
    "\n",
    "### Construya una red neuronal de regresión para predecir el precio de las viviendas. Use los datos Boston Housing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cargaremos la base de datos correspondiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "datos=load_boston()\n",
    "boston = pd.DataFrame(datos.data, columns = datos.feature_names)\n",
    "boston[\"target\"] = datos.target\n",
    "boston.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocesamiento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston.isna().sum()\n",
    "boston = boston.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Codificaremos la variable \"CHAS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "      <th>CHAS_0.0</th>\n",
       "      <th>CHAS_1.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS    NOX     RM   AGE     DIS  RAD    TAX  PTRATIO  \\\n",
       "0  0.00632  18.0   2.31  0.538  6.575  65.2  4.0900  1.0  296.0     15.3   \n",
       "1  0.02731   0.0   7.07  0.469  6.421  78.9  4.9671  2.0  242.0     17.8   \n",
       "2  0.02729   0.0   7.07  0.469  7.185  61.1  4.9671  2.0  242.0     17.8   \n",
       "\n",
       "        B  LSTAT  target  CHAS_0.0  CHAS_1.0  \n",
       "0  396.90   4.98    24.0         1         0  \n",
       "1  396.90   9.14    21.6         1         0  \n",
       "2  392.83   4.03    34.7         1         0  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston = pd.concat([boston,pd.get_dummies(boston['CHAS'], prefix='CHAS')],axis=1)\n",
    "boston.drop(['CHAS'],axis=1, inplace=True)\n",
    "boston.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creamos nuestros conjuntos de entrenamiento y prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_boston = boston.sample(frac=0.8,random_state=0)\n",
    "test_boston = boston.drop(train_boston.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CRIM</th>\n",
       "      <td>405.0</td>\n",
       "      <td>3.670339</td>\n",
       "      <td>8.977954</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>0.08265</td>\n",
       "      <td>0.26838</td>\n",
       "      <td>3.47428</td>\n",
       "      <td>88.9762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ZN</th>\n",
       "      <td>405.0</td>\n",
       "      <td>11.067901</td>\n",
       "      <td>22.688396</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>12.50000</td>\n",
       "      <td>95.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>INDUS</th>\n",
       "      <td>405.0</td>\n",
       "      <td>11.097951</td>\n",
       "      <td>6.699157</td>\n",
       "      <td>0.74000</td>\n",
       "      <td>5.32000</td>\n",
       "      <td>9.69000</td>\n",
       "      <td>18.10000</td>\n",
       "      <td>27.7400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>405.0</td>\n",
       "      <td>0.553098</td>\n",
       "      <td>0.115564</td>\n",
       "      <td>0.38500</td>\n",
       "      <td>0.44900</td>\n",
       "      <td>0.53800</td>\n",
       "      <td>0.62400</td>\n",
       "      <td>0.8710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RM</th>\n",
       "      <td>405.0</td>\n",
       "      <td>6.269768</td>\n",
       "      <td>0.690552</td>\n",
       "      <td>3.56100</td>\n",
       "      <td>5.87800</td>\n",
       "      <td>6.19300</td>\n",
       "      <td>6.61900</td>\n",
       "      <td>8.7800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count       mean        std      min      25%      50%       75%  \\\n",
       "CRIM   405.0   3.670339   8.977954  0.00632  0.08265  0.26838   3.47428   \n",
       "ZN     405.0  11.067901  22.688396  0.00000  0.00000  0.00000  12.50000   \n",
       "INDUS  405.0  11.097951   6.699157  0.74000  5.32000  9.69000  18.10000   \n",
       "NOX    405.0   0.553098   0.115564  0.38500  0.44900  0.53800   0.62400   \n",
       "RM     405.0   6.269768   0.690552  3.56100  5.87800  6.19300   6.61900   \n",
       "\n",
       "           max  \n",
       "CRIM   88.9762  \n",
       "ZN     95.0000  \n",
       "INDUS  27.7400  \n",
       "NOX     0.8710  \n",
       "RM      8.7800  "
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_boston.describe()\n",
    "train_data.pop(\"target\")\n",
    "train_data = train_data.transpose()\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = train_boston.pop(\"target\")\n",
    "test_labels = test_boston.pop(\"target\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estadarizamos nuestros datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(x):\n",
    "  return (x - train_data['mean']) / train_data['std']\n",
    "normed_train_data = norm(train_boston)\n",
    "normed_test_data = norm(test_boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A continuación elaboramos el modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Regression(Model):\n",
    "    def __init__(self):\n",
    "        super(Regression,self).__init__()\n",
    "        self.dense1 = Dense(64, activation='relu')\n",
    "        self.dropout1 = Dropout(0.4)\n",
    "        self.dense2 = Dense(64, activation='relu')\n",
    "        self.dropout2 = Dropout(0.4)\n",
    "        self.dense_out = Dense(1)\n",
    "\n",
    "    def call(self,x):\n",
    "        x = self.dense1(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.dense2(x)\n",
    "        x = self.dropout2(x)\n",
    "        return(self.dense_out(x))\n",
    "\n",
    "model = Regression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compilamos el modelo usando \"Adam\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim = tf.keras.optimizers.Adam()\n",
    "model.compile(loss='mse',\n",
    "                optimizer=optim,\n",
    "                metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Procedemos a entrenar el modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer regression_3 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
      "\n",
      "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
      "\n",
      "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
      "\n",
      "\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "....................................................................................................\n",
      "............................................................................."
     ]
    }
   ],
   "source": [
    "class PrintDot(keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs):\n",
    "    if epoch % 100 == 0: print('')\n",
    "    print('.', end='')\n",
    "\n",
    "epochs = 1000\n",
    "\n",
    "historico = model.fit(\n",
    "  normed_train_data, train_labels,\n",
    "  epochs=epochs, validation_split = 0.2, verbose=0,\n",
    "  callbacks=[PrintDot()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()\n",
    "plot_model(model, to_file='../boston_model.png', \n",
    "           show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = pd.DataFrame(historico.history)\n",
    "hist['epoch'] = historico.epoch\n",
    "hist.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(historico):\n",
    "  hist = pd.DataFrame(historico.history)\n",
    "  hist['epoch'] = historico.epoch\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Abs Error (Price)')\n",
    "  plt.plot(hist['epoch'], hist['mae'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mae'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,10])\n",
    "  plt.legend()\n",
    "\n",
    "  plt.figure()\n",
    "  plt.xlabel('Epoch')\n",
    "  plt.ylabel('Mean Square Error ($Price^2$)')\n",
    "  plt.plot(hist['epoch'], hist['mse'],\n",
    "           label='Train Error')\n",
    "  plt.plot(hist['epoch'], hist['val_mse'],\n",
    "           label = 'Val Error')\n",
    "  plt.ylim([0,50])\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n",
    "\n",
    "plot_history(historico)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, mae, mse = model.evaluate(normed_test_data, test_labels, verbose=2)\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.2f} Price\".format(mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ahora realizamos las predicciones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions = model.predict(normed_test_data).flatten()\n",
    "\n",
    "plt.scatter(test_labels, test_predictions)\n",
    "plt.xlabel('True Values (Price)')\n",
    "plt.ylabel('Predictions (Price)')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.xlim([0,plt.xlim()[1]])\n",
    "plt.ylim([0,plt.ylim()[1]])\n",
    "_ = plt.plot([-100, 100], [-100, 100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error = test_predictions - test_labels\n",
    "plt.hist(error, bins = 25)\n",
    "plt.xlabel(\"Prediction Error (Price)\")\n",
    "_ = plt.ylabel(\"Count\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
